{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from typing import cast, Any\n",
    "from keras.layers import Flatten, Conv2D, MaxPool2D, AvgPool2D, Dropout, Dense, BatchNormalization, Identity, Input, GlobalAveragePooling2D\n",
    "from keras.activations import relu\n",
    "from keras.optimizers import AdamW\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957dc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Resnet block\n",
    "class ResBlock(keras.layers.Layer):\n",
    "    def __init__(self, num_input_layers, num_output_layers, kernel_size):\n",
    "        super().__init__()\n",
    "        #For first convolutional layer\n",
    "        self.conv1 = Conv2D(num_output_layers, kernel_size=kernel_size, padding='same', stride=1, \n",
    "                                  kernel_initializer='glorot_uniform')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.relu = relu\n",
    "\n",
    "        #For second convolutional layer\n",
    "        self.conv2 = Conv2D(num_output_layers, kernel_size=kernel_size, padding='same', stride=1, \n",
    "                                  kernel_initializer='glorot_uniform')\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "        #If the input and output channels are different, we need to adjust the input\n",
    "        if num_input_layers != num_output_layers:\n",
    "            self.shortcut = Conv2D(num_output_layers, kernel_size=1, strides=1, padding='valid')\n",
    "        else:\n",
    "            self.shortcut = Identity()\n",
    "    \n",
    "    def call(self, x):\n",
    "        #First convolutional layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        #Second convolutional layer\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        #Add shortcut and apply non-linearity\n",
    "        x += self.shortcut\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7324988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(keras.Model):\n",
    "    \"\"\"Convolutional Neural Network class using Keras and Tensorflow for optimizing Hyperparameters\"\"\"\n",
    "    def __init__(self, input_shape=[75, 75, 1], batch_size=64, mode='regression'):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape = tuple([batch_size] + input_shape)\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        if (mode != 'regression') and (mode != 'classification'): #Make shure the mode is always correct\n",
    "            raise ValueError(\"The mode of the CNN can either be 'regression' or 'classification'\")\n",
    "        self.mode = mode\n",
    "\n",
    "        self.conv_layers = keras.Sequential([\n",
    "                Input(shape=(self.input_shape)),\n",
    "                ResBlock(num_input_layers=3, num_output_layers=16, kernel_size=3 ),\n",
    "                Conv2D(16, kernel_size=2, padding='valid', strides=2),\n",
    "\n",
    "                ResBlock(16, 32, 3),\n",
    "                MaxPool2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "\n",
    "                ResBlock(32, 64, 3),\n",
    "                MaxPool2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "\n",
    "                ResBlock(64, 128, 3),\n",
    "                MaxPool2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "\n",
    "                ResBlock(128, 256, 3),\n",
    "                MaxPool2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "\n",
    "                ResBlock(256, 512, 3),\n",
    "                GlobalAveragePooling2D(data_format='channels_last')\n",
    "        ])\n",
    "\n",
    "        ############################################################################################################\n",
    "        \"\"\"This is the block containing Feed Forward layers for the regression part of the assignment, \n",
    "        make a similar block for classification\"\"\"\n",
    "\n",
    "        self.regression_layers = keras.Sequential([\n",
    "            Input((batch_size, 512)),\n",
    "            Dense(256, activation='relu', kernel_initializer='RandomNormal'),\n",
    "            Dropout(0.6),\n",
    "            Dense(128, activation='relu', kernel_initializer='RandomNormal'),\n",
    "            Dropout(0.4),\n",
    "            Dense(64, activation='relu', kernel_initializer='RandomNormal'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='tanh', kernel_initializer='RandomNormal')\n",
    "        ])\n",
    "\n",
    "        ###########################################################################################################\n",
    "        \"\"\"\"You can use this to create a block that is used for classification.\"\"\"\n",
    "        self.classification_layers = keras.Sequential([\n",
    "            Input((batch_size, 512)),\n",
    "            ...\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        if self.mode == 'regression':\n",
    "            x = np.abs(self.regression_layers(x))\n",
    "        else:\n",
    "            x = self.classification_layers(x)\n",
    "        return x\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
